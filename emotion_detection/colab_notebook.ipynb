{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "from google.colab.patches import cv2_imshow\n",
    "import time\n",
    "import os\n",
    "from collections import Counter, defaultdict # for counting and storing confidence scores\n",
    "\n",
    "# path to your RAVDESS video in Google Drive\n",
    "video_path = \"/content/drive/MyDrive/RAVDESS_Videos/Actor_02/02-01-05-02-02-01-02.mp4\"\n",
    "\n",
    "# open the video file using opencv\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# check to see if OpenCV opened the video successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: The video file cannot be opened...\")\n",
    "else:\n",
    "    print(\"Processing video...\")\n",
    "\n",
    "frame_count = 0\n",
    "total_start_time = time.time()  # start tracking total video processing time\n",
    "detected_emotions = [] # store detected emotions in an array\n",
    "confidence_scores = defaultdict(float) # store confidence scores ( how confident is the detection for each emotion ) \n",
    "\n",
    "# process the video frame by frame\n",
    "while cap.isOpened():\n",
    "    frame_start_time = time.time() # track time for specific frame\n",
    "    ret, frame = cap.read() # ret is a boolean check if frame is being read successfully\n",
    "\n",
    "    if not ret:\n",
    "       break  # exit when video ends\n",
    "\n",
    "    frame_count += 1 # count processed frames#\n",
    "\n",
    "    # Skipping processing unless its every 5th frame. \n",
    "    if frame_count % 5 != 0:\n",
    "      continue\n",
    "\n",
    "    try: \n",
    "        result = DeepFace.analyze(\n",
    "            img_path=frame,\n",
    "            actions=[\"emotion\"],\n",
    "            detector_backend=\"retinaface\", # deepface emotion detection model options:(mtcnn, opencv & dlib)\n",
    "            enforce_detection=False # returns 'neutral' if no face detected rather than error if no face found.\n",
    "        )\n",
    "\n",
    "\n",
    "       # get a dominant emotion and its confidence score\n",
    "        dominant_emotion = result[0]['dominant_emotion']  # Most confident emotion\n",
    "        confidence_score = result[0]['emotion'][dominant_emotion]  # Confidence percentage\n",
    "\n",
    "        detected_emotions.append(dominant_emotion)  # Store detected emotion\n",
    "        confidence_scores[dominant_emotion] += confidence_score  # Accumulate confidence\n",
    "\n",
    "        print(f\"üß† Frame {frame_count}: Detected Emotion - {dominant_emotion} ({confidence_score:.2f}%)\")  # Log detected emotion\n",
    "\n",
    "        # Draw emotion text on frame\n",
    "        cv2.putText(frame, f\"Emotion: {dominant_emotion}\", (50, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # show frame (displays analysis frame by frame)\n",
    "        cv2_imshow(frame)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error processing frame {frame_count}:\", e)\n",
    "\n",
    "    # measure processing time for this frame\n",
    "    frame_end_time = time.time()\n",
    "    frame_processing_time = frame_end_time - frame_start_time\n",
    "    print(f\"‚è≥ Time taken for frame {frame_count}: {frame_processing_time:.4f} seconds\")\n",
    "\n",
    "# releasing resources\n",
    "cap.release()\n",
    "\n",
    "# calculate & print performance stats\n",
    "total_end_time = time.time()\n",
    "total_processing_time = total_end_time - total_start_time\n",
    "print(f\"‚úÖ Total Video Processing Time: {total_processing_time:.2f} seconds\")\n",
    "print(f\"‚ö° Average FPS: {frame_count / total_processing_time:.2f}\")\n",
    "\n",
    "# determine the most common detected emotion\n",
    "if detected_emotions:\n",
    "    most_common_emotion = Counter(detected_emotions).most_common(1)[0][0]\n",
    "    print(f\"üé≠ Most Common Emotion Detected (Occurrence-Based): {most_common_emotion}\")\n",
    "\n",
    "    # determine the emotion with highest confidence\n",
    "    highest_confidence_emotion = max(confidence_scores, key=confidence_scores.get)\n",
    "    print(f\"üîù Most Confident Emotion Detected (Confidence-Based): {highest_confidence_emotion}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No valid emotions detected.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
