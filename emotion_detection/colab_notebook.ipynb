{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "from google.colab.patches import cv2_imshow\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "from collections import Counter, defaultdict  # for counting and storing confidence scores\n",
    "\n",
    "# API endpoint where the detected emotion is sent\n",
    "RECOMMENDER_API_URL = \"NGROK_ROUTE_HERE\"\n",
    "\n",
    "# spotify Access Token\n",
    "ACCESS_TOKEN = \"ACCESS_TOKEN\"\n",
    "\n",
    "# path to your RAVDESS video in Google Drive\n",
    "video_path = \"/content/drive/MyDrive/RAVDESS_Videos/Actor_02/01-01-05-02-02-02-02.mp4\"\n",
    "\n",
    "# open the video file using opencv\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# check to see if OpenCV opened the video successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: The video file cannot be opened...\")\n",
    "else:\n",
    "    print(\"Processing video...\")\n",
    "\n",
    "frame_count = 0\n",
    "total_start_time = time.time()  # Start tracking total video processing time\n",
    "detected_emotions = []  # Store detected emotions in an array\n",
    "confidence_scores = defaultdict(float)  # Store confidence scores (how confident is the detection for each emotion)\n",
    "\n",
    "# process the video frame by frame\n",
    "while cap.isOpened():\n",
    "    frame_start_time = time.time()  # Track time for specific frame\n",
    "    ret, frame = cap.read()  # ret is a boolean check if frame is being read successfully\n",
    "\n",
    "    if not ret:\n",
    "        break  # Exit when video ends\n",
    "\n",
    "    frame_count += 1  # count processed frames\n",
    "\n",
    "    # skip processing unless it's every 5th frame\n",
    "    if frame_count % 5 != 0:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        result = DeepFace.analyze(\n",
    "            img_path=frame,\n",
    "            actions=[\"emotion\"],\n",
    "            detector_backend=\"retinaface\",  # DeepFace emotion detection model options:(mtcnn, opencv & dlib)\n",
    "            enforce_detection=False  # Returns 'neutral' if no face detected rather than error if no face found.\n",
    "        )\n",
    "\n",
    "        # get a dominant emotion and its confidence score\n",
    "        dominant_emotion = result[0]['dominant_emotion']  # Most confident emotion\n",
    "        confidence_score = result[0]['emotion'][dominant_emotion]  # Confidence percentage\n",
    "\n",
    "        detected_emotions.append(dominant_emotion)  # Store detected emotion\n",
    "        confidence_scores[dominant_emotion] += confidence_score  # Accumulate confidence\n",
    "\n",
    "        print(f\"üß† Frame {frame_count}: Detected Emotion - {dominant_emotion} ({confidence_score:.2f}%)\")  # Log detected emotion\n",
    "\n",
    "        # Draw emotion text on frame\n",
    "        cv2.putText(frame, f\"Emotion: {dominant_emotion}\", (50, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Show frame (displays analysis frame by frame)\n",
    "        cv2_imshow(frame)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error processing frame {frame_count}:\", e)\n",
    "\n",
    "    # Measure processing time for this frame\n",
    "    frame_end_time = time.time()\n",
    "    frame_processing_time = frame_end_time - frame_start_time\n",
    "    print(f\"‚è≥ Time taken for frame {frame_count}: {frame_processing_time:.4f} seconds\")\n",
    "\n",
    "# Releasing resources\n",
    "cap.release()\n",
    "\n",
    "# Calculate & print performance stats\n",
    "total_end_time = time.time()\n",
    "total_processing_time = total_end_time - total_start_time\n",
    "print(f\"‚úÖ Total Video Processing Time: {total_processing_time:.2f} seconds\")\n",
    "print(f\"‚ö° Average FPS: {frame_count / total_processing_time:.2f}\")\n",
    "\n",
    "# determine the most common detected emotion\n",
    "if detected_emotions:\n",
    "    most_common_emotion = Counter(detected_emotions).most_common(1)[0][0]\n",
    "    highest_confidence_emotion = max(confidence_scores, key=confidence_scores.get)\n",
    "\n",
    "    # final emotion choice (can be changed to use the confidence-based approach)\n",
    "    final_detected_emotion = most_common_emotion\n",
    "\n",
    "    print(f\"üé≠ Most Common Emotion Detected (Occurrence-Based): {most_common_emotion}\")\n",
    "    print(f\"üîù Most Confident Emotion Detected (Confidence-Based): {highest_confidence_emotion}\")\n",
    "    print(f\"üöÄ Sending emotion to recommender...\")\n",
    "\n",
    "      # send the detected emotion to recommender API\n",
    "    payload = {\"emotion\": final_detected_emotion, \"access_token\": ACCESS_TOKEN}  # include the access token\n",
    "    try:\n",
    "        response = requests.post(RECOMMENDER_API_URL, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            print(\"‚úÖ Recommender API response:\", response_data)\n",
    "\n",
    "            # show playlist if created\n",
    "            if response_data.get(\"playlist_created\"):\n",
    "                print(f\"üéµ Playlist Created: {response_data['playlist_created']['playlist_url']}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Failed to send emotion to API. Status Code: {response.status_code}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error sending emotion to API: {e}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
