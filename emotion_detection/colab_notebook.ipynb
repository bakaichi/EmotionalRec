{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "from google.colab.patches import cv2_imshow\n",
    "import time\n",
    "import os\n",
    "\n",
    "# path to your RAVDESS video in Google Drive\n",
    "video_path = \"/content/drive/MyDrive/RAVDESS_Videos/Actor_02/02-01-05-02-02-01-02.mp4\"\n",
    "\n",
    "# open the video file using opencv\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# check to see if OpenCV opened the video successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: The video file cannot be opened...\")\n",
    "else:\n",
    "    print(\"Processing video...\")\n",
    "\n",
    "frame_count = 0\n",
    "total_start_time = time.time()  # start tracking total video processing time\n",
    "\n",
    "# process the video frame by frame\n",
    "while cap.isOpened():\n",
    "    frame_start_time = time.time() # track time for specific frame\n",
    "    ret, frame = cap.read() # ret is a boolean check if frame is being read successfully\n",
    "\n",
    "    if not ret:\n",
    "       break  # exit when video ends\n",
    "\n",
    "    frame_count += 1 # count processed frames\n",
    "\n",
    "    try: \n",
    "        result = DeepFace.analyze(\n",
    "            img_path=frame,\n",
    "            actions=[\"emotion\"],\n",
    "            detector_backend=\"retinaface\", # deepface emotion detection model options:(mtcnn, opencv & dlib)\n",
    "            enforce_detection=False # returns 'neutral' if no face detected rather than error if no face found.\n",
    "        )\n",
    "\n",
    "\n",
    "       # get a dominant emotion\n",
    "        dominant_emotion = result[0]['dominant_emotion'] # extracts emotion with highest confidence score. \n",
    "        print(f\"üß† Frame {frame_count}: Detected Emotion - {dominant_emotion}\") # logs the detected emotion in terminal and frame information\n",
    "\n",
    "        # Draw emotion text on frame\n",
    "        cv2.putText(frame, f\"Emotion: {dominant_emotion}\", (50, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "     # show frame (displays analysis frame by frame)\n",
    "        cv2_imshow(frame)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error processing frame {frame_count}:\", e)\n",
    "\n",
    "    # measure processing time for this frame\n",
    "    frame_end_time = time.time()\n",
    "    frame_processing_time = frame_end_time - frame_start_time\n",
    "    print(f\"‚è≥ Time taken for frame {frame_count}: {frame_processing_time:.4f} seconds\")\n",
    "\n",
    "\n",
    "# releasing resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows() # if run on local machine without colab\n",
    "\n",
    "# calculate & print performance stats\n",
    "total_end_time = time.time()\n",
    "total_processing_time = total_end_time - total_start_time\n",
    "print(f\"‚úÖ Total Video Processing Time: {total_processing_time:.2f} seconds\")\n",
    "print(f\"‚ö° Average FPS: {frame_count / total_processing_time:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
