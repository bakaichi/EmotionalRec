{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!pip install deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "# path to your RAVDESS video in Google Drive\n",
    "video_path = \"/content/drive/MyDrive/RAVDESS_Videos/Actor_02/02-01-05-02-02-01-02.mp4\"\n",
    "\n",
    "# open the video file using opencv\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# check to see if OpenCV opened the video successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: The video file cannot be opened...\")\n",
    "else:\n",
    "    print(\"Processing video...\")\n",
    "\n",
    "\n",
    "# process the video frame by frame\n",
    "while cap.isOpened():\n",
    "# ret is a boolean check if frame is being read successfully\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "       break  # exit when video ends\n",
    "\n",
    "\n",
    "    try: \n",
    "        result = DeepFace.analyze(\n",
    "            img_path=frame,\n",
    "            actions=[\"emotion\"],\n",
    "            detector_backend=\"retinaface\", # deepface emotion detection model options:(mtcnn, opencv & dlib)\n",
    "            enforce_detection=False # returns 'neutral' if no face detected rather than error if no face found.\n",
    "        )\n",
    "\n",
    "\n",
    "       # get a dominant emotion\n",
    "        dominant_emotion = result[0]['dominant_emotion'] # extracts emotion with highest confidence score. \n",
    "        print(\"Detected Emotion:\", dominant_emotion) # logs the detected emotion in terminal\n",
    "\n",
    "        # Draw emotion text on frame\n",
    "        cv2.putText(frame, f\"Emotion: {dominant_emotion}\", (50, 50),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "     # show frame (displays frame by frame analysis)\n",
    "        cv2_imshow(frame)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error processing frame:\", e)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
